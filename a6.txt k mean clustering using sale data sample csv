import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns 
import pandas as pd
import seaborn as sns 
from sklearn import preprocessing
from yellowbrick.cluster import KElbowVisualizer
from sklearn.cluster import KMeans

from collections import Counter




data = pd.read_csv("C:\\Users\\Admin\\Downloads\\ML Codes\\ML Codes\\sales_data_sample.csv", encoding='Latin-1')
print(data)

print(data.shape) 
 
print(data.isnull().sum() )
 



data.drop(["ORDERNUMBER", "PRICEEACH", "ORDERDATE", "PHONE", "ADDRESSLINE1", "ADDRESSLINE2", "CITY", "STATE", "TERRITORY", "POSTALCODE", "CONTACTLASTNAME", "CONTACTFIRSTNAME"], axis = 1, inplace=True) 
print(data.head() )
print(data.isnull().sum() )
print(data.describe() )



sns.countplot(data = data , x = 'STATUS') 
sns.histplot(x = 'SALES' , hue = 'PRODUCTLINE', data = data,element="poly") 
data['PRODUCTLINE'].unique() 
data.drop_duplicates(inplace=True) 
data.info() 
list_cat = data.select_dtypes(include=['object']).columns.tolist() 
list_cat 
for i in list_cat:  
    sns.countplot(data = data ,x = i)
    plt.xticks(rotation = 90)   
    plt.show() 
 
le = preprocessing.LabelEncoder() 
 
 
for i in list_cat:
    data[i]= le.fit_transform(data[i]) 
 
data.info() 
data['SALES'] = data['SALES'].astype(int) 
data.info() 
data.describe() 
X = data[['SALES','PRODUCTCODE']] 
data.columns 




model = KMeans()
visualizer = KElbowVisualizer(model, k=(1,12)).fit(X)
visualizer.show() 
kmeans = KMeans(n_clusters=4, init='k-means++', random_state=0).fit(X)
kmeans.labels_  
 
kmeans.inertia_ 
 
kmeans.n_iter_
kmeans.cluster_centers_ 
 

Counter(kmeans.labels_) 
 
sns.scatterplot(data=X, x="SALES", y="PRODUCTCODE", hue=kmeans.labels_)
plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],marker="X", c="r", s=80, label="centroids") 
plt.legend()
plt.show() 



















Sure, let's break down the steps for implementing K-Means clustering or Hierarchical clustering on the "sales_data_sample.csv" dataset and determining the number of clusters using the elbow method:

1. **Understand the Objective**:
   - The goal is to cluster or group similar sales data together, potentially identifying patterns or segments within the data.

2. **Load the Dataset**:
   - Start by loading the "sales_data_sample.csv" dataset into your programming environment. This dataset contains information about sales transactions, such as customer names, product details, sales quantities, and prices.

3. **Data Preprocessing**:
   - Examine the dataset for missing values, outliers, and any necessary data cleaning. Ensure that the data is clean and ready for clustering.

4. **Feature Selection**:
   - Identify the features (attributes) in the dataset that you want to use for clustering. In this context, features could be items, sales quantities, or customer attributes.

5. **Normalization (if needed)**:
   - If the features have different units or scales, it may be necessary to normalize them to ensure that all features are equally weighted during clustering.

6. **Choose the Clustering Method**:
   - Decide whether you want to use K-Means or Hierarchical clustering for the analysis. K-Means is a method to partition data into K clusters, while Hierarchical clustering creates a tree-like structure of clusters.

7. **Determine the Number of Clusters using the Elbow Method**:
   - For K-Means, it's important to determine the optimal number of clusters (K). The elbow method helps you find a suitable K value:
     - Run K-Means with different values of K, starting from 2 and increasing incrementally.
     - For each K, calculate the sum of squared distances (inertia) of data points to their respective cluster centroids. This is a measure of how compact the clusters are.
     - Plot the values of K against the corresponding inertia.
     - Look for an "elbow point" on the graph where the inertia starts to level off. This point indicates a suitable K value.

8. **Cluster the Data**:
   - Once you've determined the optimal number of clusters (K), use the selected clustering method (K-Means or Hierarchical) to group the sales data into these clusters.

9. **Visualize Clusters (if needed)**:
   - Visualize the clustered data to understand how the data points are grouped. You can use scatter plots, dendrograms, or other visualization techniques.

10. **Interpret Results**:
    - Examine the characteristics of each cluster to understand what sets them apart. For example, you can analyze common customer behavior or sales patterns within each cluster.

11. **Evaluate the Clustering**:
    - Assess the quality of the clustering results using appropriate metrics. For K-Means, you can use metrics like silhouette score or Davies-Bouldin index to measure the quality of clusters.

By following these steps, you can implement K-Means or Hierarchical clustering on the sales data and determine the number of clusters using the elbow method. This will help you identify patterns or segments within the data, potentially providing valuable insights for your business or analysis.
