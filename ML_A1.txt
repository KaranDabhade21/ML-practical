import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

uber = pd.read_csv('C:\\Users\\Admin\\Downloads\\ML Codes\\ML Codes\\uber.csv')

uber.head()


uber.info()

uber.isnull().sum()

uber_2 = uber.drop(['Unnamed: 0','key'],axis=1)
uber_2.dropna(axis=0,inplace=True)

uber_2.isnull().sum()
#uber_2.describe()

def haversine (lon_1, lon_2, lat_1, lat_2):
    
    lon_1, lon_2, lat_1, lat_2 = map(np.radians, [lon_1, lon_2, lat_1, lat_2])  #Degrees to Radians
    
    
    diff_lon = lon_2 - lon_1
    diff_lat = lat_2 - lat_1
    

    km = 2 * 6371 * np.arcsin(np.sqrt(np.sin(diff_lat/2.0)**2 + 
                                      np.cos(lat_1) * np.cos(lat_2) * np.sin(diff_lon/2.0)**2))
    
    return km

uber_2['Distance']= haversine(uber_2['pickup_longitude'],uber_2['dropoff_longitude'],
                             uber_2['pickup_latitude'],uber_2['dropoff_latitude'])

uber_2['Distance'] = uber_2['Distance'].astype(float).round(2)    # Round-off Optional

uber_2.head()

plt.scatter(uber_2['Distance'], uber_2['fare_amount'])
plt.xlabel("Distance")
plt.ylabel("fare_amount")

uber_2.drop(uber_2[uber_2['Distance'] > 60].index, inplace = True)
uber_2.drop(uber_2[uber_2['Distance'] == 0].index, inplace = True)
uber_2.drop(uber_2[uber_2['fare_amount'] == 0].index, inplace = True)
uber_2.drop(uber_2[uber_2['fare_amount'] < 0].index, inplace = True)

uber_2.drop(uber_2[(uber_2['fare_amount']>100) & (uber_2['Distance']<1)].index, inplace = True )
uber_2.drop(uber_2[(uber_2['fare_amount']<100) & (uber_2['Distance']>100)].index, inplace = True )

uber_2.info()

uber_2['pickup_datetime'] = pd.to_datetime(uber_2['pickup_datetime'])

uber_2['Year'] = uber_2['pickup_datetime'].apply(lambda time: time.year)
uber_2['Month'] = uber_2['pickup_datetime'].apply(lambda time: time.month)
uber_2['Day'] = uber_2['pickup_datetime'].apply(lambda time: time.day)
uber_2['Day of Week'] = uber_2['pickup_datetime'].apply(lambda time: time.dayofweek)
uber_2['Day of Week_num'] = uber_2['pickup_datetime'].apply(lambda time: time.dayofweek)
uber_2['Hour'] = uber_2['pickup_datetime'].apply(lambda time: time.hour)

day_map = {0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}
uber_2['Day of Week'] = uber_2['Day of Week'].map(day_map)

uber_2['counter'] = 1

uber_2['pickup'] = uber_2['pickup_latitude'].astype(str) + "," + uber_2['pickup_longitude'].astype(str)   
uber_2['drop off'] = uber_2['dropoff_latitude'].astype(str) + "," + uber_2['dropoff_longitude'].astype(str)

uber_2.head()

import statistics as st

print("Mean of fare prices is % s "
         % (st.mean(uber_2['fare_amount'])))

print("Median of fare prices is % s "
         % (st.median(uber_2['fare_amount'])))

print("Standard Deviation of Fare Prices is % s "
                % (st.stdev(uber_2['fare_amount'])))

import statistics as st

print("Mean of Distance is % s "
         % (st.mean(uber_2['Distance'])))

print("Median of Distance is % s "
         % (st.median(uber_2['Distance'])))

print("Standard Deviation of Distance is % s "
                % (st.stdev(uber_2['Distance'])))

X = uber_2['Distance'].values.reshape(-1, 1)        #Independent Variable
y = uber_2['fare_amount'].values.reshape(-1, 1)     #Dependent Variable

from sklearn.preprocessing import StandardScaler
std = StandardScaler()
y_std = std.fit_transform(y)
print(y_std)

x_std = std.fit_transform(X)
print(x_std)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x_std, y_std, test_size=0.2, random_state=0)

from sklearn.linear_model import LinearRegression
l_reg = LinearRegression()
l_reg.fit(X_train, y_train)

print("Training set score: {:.2f}".format(l_reg.score(X_train, y_train)))
print("Test set score: {:.7f}".format(l_reg.score(X_test, y_test)))

y_pred = l_reg.predict(X_test)
df = {'Actual': y_test, 'Predicted': y_pred}

from tabulate import tabulate
print(tabulate(df, headers = 'keys', tablefmt = 'psql'))

from sklearn import metrics
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Absolute % Error:', metrics.mean_absolute_percentage_error(y_test, y_pred),"%")
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

print(l_reg.intercept_)
print(l_reg.coef_)













Predicting the price of an Uber ride from a given pickup point to the agreed drop-off location involves several data analysis and machine learning tasks. Here's a step-by-step explanation of each task:

1. Pre-processing the dataset:
   - The first step is to gather and pre-process the dataset. This dataset may include features such as pickup location, drop-off location, ride duration, ride distance, time of day, and other relevant variables.
   - Data pre-processing involves handling missing values, data cleaning (removing duplicates or irrelevant data), and encoding categorical variables if necessary (converting non-numeric data into numerical format using techniques like one-hot encoding).
   - It's also crucial to split the dataset into training and testing sets to train and evaluate the machine learning models effectively.

2. Identify outliers:
   - Outliers are data points that significantly deviate from the typical patterns in the dataset and can negatively impact the performance of regression models. Identifying and handling outliers is important.
   - Common methods for identifying outliers include statistical techniques like Z-scores, visualization tools like box plots, and domain knowledge to determine if certain values are unrealistic.

3. Check the correlation:
   - Correlation analysis helps you understand the relationships between different features and the target variable (Uber ride price in this case).
   - Calculate and visualize correlation coefficients between features and the target variable. Positive or negative correlations can help in feature selection and model building.

4. Implement linear regression and random forest regression models:
   - Linear Regression: Linear regression is a simple model that assumes a linear relationship between the input features and the target variable. It finds the best-fitting line that minimizes the sum of squared errors between predicted and actual values.
   - Random Forest Regression: Random forest is an ensemble model that combines multiple decision trees to improve prediction accuracy. It's particularly useful when dealing with complex, non-linear relationships in the data.

5. Evaluate the models and compare their respective scores:
   - To evaluate the models, you can use various metrics, including but not limited to:
     - R-squared (R2): It measures the proportion of the variance in the target variable explained by the model. A higher R2 indicates a better fit.
     - Root Mean Squared Error (RMSE): RMSE measures the average prediction error in the same units as the target variable. Lower RMSE values indicate better model accuracy.
     - Mean Absolute Error (MAE): MAE is another metric to measure prediction accuracy, and it's less sensitive to outliers compared to RMSE.
   - Apply both linear regression and random forest regression to the test dataset and calculate these metrics for each model.
   - Compare the R2, RMSE, and other relevant metrics to determine which model provides the best predictive performance for the Uber ride pricing task.

It's important to note that data preprocessing and feature engineering may have a significant impact on the model's performance, so a thorough understanding of the data and domain knowledge is crucial. Additionally, you can further fine-tune and optimize the models to achieve better results, like hyperparameter tuning for the random forest model or using feature selection techniques.






Sure, let's break it down in simple terms:

1. **Pre-processing the dataset:** This step involves getting the data ready for analysis. It's like cleaning your room before you can work or play. You make sure there are no messy or missing things.

2. **Identify outliers:** Outliers are like those weird or unusual things that don't belong in your room. You need to find and remove them because they can mess up your predictions.

3. **Check the correlation:** This is like checking if certain things in your room go together. For example, if you notice that when it's sunny outside, your room is warmer, there's a correlation between sunshine and warmth.

4. **Implement linear regression and random forest regression models:** Imagine you have two different ways to guess how much your Uber ride will cost. One way is like drawing a straight line on a graph, and the other is like using a magical forest of trees to make your guess. These are the two methods (models) you'll use to predict the Uber ride price.

5. **Evaluate the models and compare their respective scores:** After trying both methods, you want to see which one is better at guessing the Uber price. You use scores to do this, like:
   - R2, which tells you how good your guess is compared to reality (the higher, the better).
   - RMSE, which measures how close your guess is to the real price (lower is better).
   - MAE, which is another way to check how close your guess is to the real price.

In the end, you'll pick the method (model) that gives you the best guess for your Uber ride price, and that's how you predict it.
